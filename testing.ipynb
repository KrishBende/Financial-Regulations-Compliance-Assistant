{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73874db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba3b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # Remove page numbers (standalone digits)\n",
    "    text = re.sub(r\"\\n?\\s*\\d+\\s*\\n?\", \" \", text)\n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    full_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text() or \"\"\n",
    "            full_text += text + \"\\n\"\n",
    "    return clean_text(full_text)\n",
    "\n",
    "def chunk_text(text: str, chunk_size=500, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "def process_pdfs():\n",
    "    for pdf_file in RAW_DIR.glob(\"*.pdf\"):\n",
    "        print(f\"Processing: {pdf_file.name}\")\n",
    "        text = extract_text_from_pdf(pdf_file)\n",
    "        chunks = chunk_text(text)\n",
    "\n",
    "        # Save as JSON\n",
    "        output_file = PROCESSED_DIR / f\"{pdf_file.stem}.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(\n",
    "                [{\"chunk_id\": i, \"text\": chunk} for i, chunk in enumerate(chunks)],\n",
    "                f,\n",
    "                ensure_ascii=False,\n",
    "                indent=2\n",
    "            )\n",
    "        print(f\"Saved {len(chunks)} chunks → {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57500a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: banking_regulation_act_1949.pdf\n",
      "Saved 993 chunks → data/processed/banking_regulation_act_1949.json\n",
      "Processing: sebi_1999.pdf\n",
      "Saved 167 chunks → data/processed/sebi_1999.json\n",
      "Processing: sebi_2023.pdf\n",
      "Saved 45 chunks → data/processed/sebi_2023.json\n",
      "Processing: sebi_2015.pdf\n",
      "Saved 52 chunks → data/processed/sebi_2015.json\n"
     ]
    }
   ],
   "source": [
    "process_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae52e82",
   "metadata": {},
   "source": [
    "Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba13b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/Desktop/DSML/ML-Projects/ResumeProjects/Financial_Compliance_Rag/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f2a58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 40/40 [00:56<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "\n",
    "# Load all chunks\n",
    "documents = []\n",
    "for file in PROCESSED_DIR.glob(\"*.json\"):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "        for c in chunks:\n",
    "            documents.append({\n",
    "                \"text\": c[\"text\"],\n",
    "                \"source\": file.stem,   # keep track of original PDF\n",
    "                \"chunk_id\": c[\"chunk_id\"]\n",
    "            })\n",
    "\n",
    "# Load small embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "embeddings = model.encode([doc[\"text\"] for doc in documents], show_progress_bar=True)\n",
    "\n",
    "# Convert to numpy array (FAISS needs float32)\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "# Dimensions of embeddings\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_index.bin\")\n",
    "\n",
    "# Save metadata separately\n",
    "with open(\"faiss_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b056f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=3):\n",
    "    # Embed query\n",
    "    query_vector = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    \n",
    "    # Search in FAISS\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx == -1:  # safeguard\n",
    "            continue\n",
    "        results.append({\n",
    "            \"text\": documents[idx][\"text\"],\n",
    "            \"source\": documents[idx][\"source\"],\n",
    "            \"chunk_id\": documents[idx][\"chunk_id\"],\n",
    "            \"distance\": float(dist)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cab9aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sebi_2023 - chunk 24] (score=0.7631)\n",
      "discretion of the authority competent to grant reward. The decision of Competent\n",
      "Authority on such claim shall not be subject to challenge before any Court of law\n",
      "by the informant or any other person on his behalf.\n",
      "ii. The reward under these Guidelines shall not be assigned to any other person by\n",
      "the informant. The Competent Authority may however grant reward to heirs or \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 28] (score=0.7014)\n",
      "the Competent Authority to grant the reward by passing an order in this regard. The\n",
      "Competent Authority shall pass the order based on the recommendation made by\n",
      "the Informant Reward Committee. . Circumstances for determining the Amount of Reward.\n",
      "In recommending the reward amount, the Informant Reward Committee shall\n",
      "consider the following:\n",
      "a) The accuracy of the information given by the informant;\n",
      "b) The extent and nature of the assistance rendered by the informant; \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 27] (score=0.6552)\n",
      "Protection and Education Fund;\n",
      "ii. The Informant Reward Committee shall give its recommendations to the\n",
      "Competent Authority on the following matters:\n",
      "(a) eligibility of Informant for reward;\n",
      "(b) determination of amount of reward payable to Informant. . Competent Authority to Grant Reward.\n",
      "The Executive Director in-charge of the Recovery and Refund Department shall be\n",
      "the Competent Authority to grant the reward by passing an order in this regard. The \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 17] (score=0.6013)\n",
      "When an informant furnishes any information or documents in the expectation of a\n",
      "reward, following written undertaking shall be taken from him which shall be part of\n",
      "Form-B: -\n",
      "a) That he is aware that the information or documents furnished by him does not ipso\n",
      "facto confer on him the right to any reward and that he shall be bound by the decision\n",
      "of the competent authority of the Board in this regard.\n",
      "b) That he is aware that the extent of reward depends on the precision of the \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 25] (score=0.5937)\n",
      "the informant. The Competent Authority may however grant reward to heirs or\n",
      "nominees of an informant in the event of his death before payment of the reward. . Constitution and Functions of Informant Reward Committee\n",
      "i. For the purpose of recommending the eligibility of reward and the amount thereof,\n",
      "there shall be constituted an Informant Reward Committee comprising the Chief\n",
      "General Manager of Recovery and Refund Department, the concerned Recovery \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "user_question=\"Who will be the competent authority to grant reward?\"\n",
    "results = search(user_question, top_k=5)\n",
    "for r in results:\n",
    "    print(f\"[{r['source']} - chunk {r['chunk_id']}] (score={r['distance']:.4f})\")\n",
    "    print(r[\"text\"][:1500], \"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b0cfe",
   "metadata": {},
   "source": [
    "LLM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e60dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "openrouter_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b790f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Reply:\n",
      "**The Executive Director in-charge of the Recovery and Refund Department** shall be the Competent Authority to grant the reward by passing an order in this regard.\n",
      "\n",
      "*Source: Extract 3 - [sebi_2023 - chunk 27]*\n"
     ]
    }
   ],
   "source": [
    "rag_context=\"\"\n",
    "count=1\n",
    "for r in results:\n",
    "    rag_context+=f\"Extract {count}- \"\n",
    "    rag_context+=f\"[{r['source']} - chunk {r['chunk_id']}] (score={r['distance']:.4f}) \\n\"\n",
    "    rag_context+=f\"{r[\"text\"][:1500]} \\n\\n\"\n",
    "    count+=1\n",
    "\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"x-ai/grok-4-fast:free\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            You are a financial and legal compliance assistant. Answer the question using the provided RAG context ONLY. Always cite the source.\n",
    "            If relevant context is not provided- say “Relevant information not found in database.”\n",
    "            Question: {user_question}\n",
    "            Context: {rag_context}\n",
    "    \"\"\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    response.raise_for_status()\n",
    "    response_data = response.json()\n",
    "\n",
    "    model_reply = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Model Reply:\")\n",
    "    print(model_reply)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred during the API request: {e}\")\n",
    "    if hasattr(e, 'response') and e.response is not None:\n",
    "        print(f\"Response content: {e.response.text}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to decode JSON response.\")\n",
    "    print(f\"Raw response content: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f22a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
