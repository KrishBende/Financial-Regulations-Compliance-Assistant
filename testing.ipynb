{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73874db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba3b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # Remove page numbers (standalone digits)\n",
    "    text = re.sub(r\"\\n?\\s*\\d+\\s*\\n?\", \" \", text)\n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    full_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text() or \"\"\n",
    "            full_text += text + \"\\n\"\n",
    "    return clean_text(full_text)\n",
    "\n",
    "def chunk_text(text: str, chunk_size=500, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "def process_pdfs():\n",
    "    for pdf_file in RAW_DIR.glob(\"*.pdf\"):\n",
    "        print(f\"Processing: {pdf_file.name}\")\n",
    "        text = extract_text_from_pdf(pdf_file)\n",
    "        chunks = chunk_text(text)\n",
    "\n",
    "        # Save as JSON\n",
    "        output_file = PROCESSED_DIR / f\"{pdf_file.stem}.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(\n",
    "                [{\"chunk_id\": i, \"text\": chunk} for i, chunk in enumerate(chunks)],\n",
    "                f,\n",
    "                ensure_ascii=False,\n",
    "                indent=2\n",
    "            )\n",
    "        print(f\"Saved {len(chunks)} chunks → {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57500a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: banking_regulation_act_1949.pdf\n",
      "Saved 993 chunks → data/processed/banking_regulation_act_1949.json\n",
      "Processing: sebi_1999.pdf\n",
      "Saved 167 chunks → data/processed/sebi_1999.json\n",
      "Processing: sebi_2023.pdf\n",
      "Saved 45 chunks → data/processed/sebi_2023.json\n",
      "Processing: sebi_2015.pdf\n",
      "Saved 52 chunks → data/processed/sebi_2015.json\n"
     ]
    }
   ],
   "source": [
    "process_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae52e82",
   "metadata": {},
   "source": [
    "Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba13b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/Desktop/DSML/ML-Projects/ResumeProjects/Financial_Compliance_Rag/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2a58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1257 chunks from 4 documents\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "\n",
    "# Load all chunks\n",
    "documents = []\n",
    "for file in PROCESSED_DIR.glob(\"*.json\"):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "        for c in chunks:\n",
    "            documents.append({\n",
    "                \"text\": c[\"text\"],\n",
    "                \"source\": file.stem,   # keep track of original PDF\n",
    "                \"chunk_id\": c[\"chunk_id\"]\n",
    "            })\n",
    "\n",
    "# Load small embedding model\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "embeddings = model.encode([doc[\"text\"] for doc in documents], show_progress_bar=True)\n",
    "\n",
    "# Convert to numpy array (FAISS needs float32)\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "# Dimensions of embeddings\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_index.bin\")\n",
    "\n",
    "# Save metadata separately\n",
    "with open(\"faiss_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documents, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b056f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=3):\n",
    "    # Embed query\n",
    "    query_vector = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    \n",
    "    # Search in FAISS\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx == -1:  # safeguard\n",
    "            continue\n",
    "        results.append({\n",
    "            \"text\": documents[idx][\"text\"],\n",
    "            \"source\": documents[idx][\"source\"],\n",
    "            \"chunk_id\": documents[idx][\"chunk_id\"],\n",
    "            \"distance\": float(dist)\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cab9aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sebi_2023 - chunk 27] (score=30.6410)\n",
      "Protection and Education Fund;\n",
      "ii. The Informant Reward Committee shall give its recommendations to the\n",
      "Competent Authority on the following matters:\n",
      "(a) eligibility of Informant for reward;\n",
      "(b) determination of amount of reward payable to Informant. . Competent Authority to Grant Reward.\n",
      "The Executive Director in-charge of the Recovery and Refund Department shall be\n",
      "the Competent Authority to grant the reward by passing an order in this regard. The \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 24] (score=29.7644)\n",
      "discretion of the authority competent to grant reward. The decision of Competent\n",
      "Authority on such claim shall not be subject to challenge before any Court of law\n",
      "by the informant or any other person on his behalf.\n",
      "ii. The reward under these Guidelines shall not be assigned to any other person by\n",
      "the informant. The Competent Authority may however grant reward to heirs or \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 28] (score=29.5334)\n",
      "the Competent Authority to grant the reward by passing an order in this regard. The\n",
      "Competent Authority shall pass the order based on the recommendation made by\n",
      "the Informant Reward Committee. . Circumstances for determining the Amount of Reward.\n",
      "In recommending the reward amount, the Informant Reward Committee shall\n",
      "consider the following:\n",
      "a) The accuracy of the information given by the informant;\n",
      "b) The extent and nature of the assistance rendered by the informant; \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 23] (score=27.8243)\n",
      "Any proposal / recommendation and approval for Final reward may be made after\n",
      "recovery of dues has been completed with respect to the asset for which\n",
      "information was received. . Reward as Ex-gratia payment\n",
      "i. Reward in accordance with these Guidelines is discretionary and shall be in the\n",
      "nature of ex-gratia payment subject to these Guidelines and shall be granted at the\n",
      "discretion of the authority competent to grant reward. The decision of Competent \n",
      "---\n",
      "\n",
      "[sebi_2023 - chunk 0] (score=27.3493)\n",
      "SECURITIES AND EXCHANGE BOARD OF INDIA (GRANT OF REWARD TO\n",
      "INFORMANT UNDER RECOVERY PROCEEDINGS) GUIDELINES, In exercise of the powers conferred under Section ( ) of the Securities and Exchange\n",
      "Board of India Act, , the Securities and Exchange Board of India hereby makes the\n",
      "following Guidelines to regulate the grant and payment of reward to an informant who\n",
      "provides credible information about the assets of the defaulter under recovery\n",
      "proceedings: . Short Title and Commencement. \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "user_question=\"Who will be the competent authority to grant reward?\"\n",
    "results = search(user_question, top_k=5)\n",
    "for r in results:\n",
    "    print(f\"[{r['source']} - chunk {r['chunk_id']}] (score={r['distance']:.4f})\")\n",
    "    print(r[\"text\"][:1500], \"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b0cfe",
   "metadata": {},
   "source": [
    "LLM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e60dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "openrouter_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b790f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Reply:\n",
      "**The Executive Director in-charge of the Recovery and Refund Department** shall be the Competent Authority to grant the reward by passing an order in this regard.\n",
      "\n",
      "*Source: [sebi_2023 - chunk 27]*\n"
     ]
    }
   ],
   "source": [
    "rag_context=\"\"\n",
    "count=1\n",
    "for r in results:\n",
    "    rag_context+=f\"Extract {count}- \"\n",
    "    rag_context+=f\"[{r['source']} - chunk {r['chunk_id']}] (score={r['distance']:.4f}) \\n\"\n",
    "    rag_context+=f\"{r[\"text\"][:1500]} \\n\\n\"\n",
    "    count+=1\n",
    "\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"x-ai/grok-4-fast:free\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            You are a financial and legal compliance assistant. Answer the question using the provided RAG context ONLY. Always cite the source.\n",
    "            If relevant context is not provided- say “Relevant information not found in database.”\n",
    "            Question: {user_question}\n",
    "            Context: {rag_context}\n",
    "    \"\"\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    response.raise_for_status()\n",
    "    response_data = response.json()\n",
    "\n",
    "    model_reply = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(\"Model Reply:\")\n",
    "    print(model_reply)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred during the API request: {e}\")\n",
    "    if hasattr(e, 'response') and e.response is not None:\n",
    "        print(f\"Response content: {e.response.text}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to decode JSON response.\")\n",
    "    print(f\"Raw response content: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
